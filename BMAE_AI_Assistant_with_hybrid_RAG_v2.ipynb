{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dodeeric/langchain-ai-assistant-with-hybrid-rag/blob/main/BMAE_AI_Assistant_with_hybrid_RAG_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uN1I_30g_aFm"
      },
      "source": [
        "# AI Assistant (LLM Chatbot) with Hybrid RAG\n",
        "Hybrid RAG: keyword search (bm25) and semantic search (vector db)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tm_zLVsh-276"
      },
      "source": [
        "## Scape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "Kei890_wuANp"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade --quiet bs4 langchain-community\n",
        "\n",
        "import requests, json, time, bs4\n",
        "from bs4 import BeautifulSoup\n",
        "from langchain_community.document_loaders import WebBaseLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "JQm75HI5g5e0"
      },
      "outputs": [],
      "source": [
        "# Function: Scrape Commons Summary = scs\n",
        "# Scrape the summary section and the metadata fields of a Wikimedia Commons web page.\n",
        "\n",
        "def scrape_commons_summary(url):\n",
        "    \"\"\"\n",
        "    Scrape the summary section and the metadata fields of a Wikimedia Commons web page.\n",
        "    Input: URL of the page\n",
        "    Output: JSON with: url: url, metadata: metadata, text: summary text\n",
        "    \"\"\"\n",
        "\n",
        "    # Get the summary\n",
        "    loader = WebBaseLoader(\n",
        "        web_paths=(url,),\n",
        "        bs_kwargs=dict(\n",
        "            parse_only=bs4.SoupStrainer(\n",
        "                class_=(\"hproduct commons-file-information-table\")\n",
        "            )\n",
        "        ),\n",
        "    )\n",
        "    summary = loader.load()\n",
        "    # Covert Document type into string type\n",
        "    summary = summary[0].page_content\n",
        "\n",
        "    # Get the metadata\n",
        "    # Get the HTML code\n",
        "    response = requests.get(url)\n",
        "    # Transform the HTML code from a Response object type into a BeautifulSoup object type to be scraped by Beautiful Soup\n",
        "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "    # Get the metadata fields\n",
        "    metadata = {} # Empty dictionary\n",
        "    # Find all the meta tags in the HTML\n",
        "    meta_tags = soup.find_all(\"meta\")\n",
        "    # Loop through the meta tags\n",
        "    for tag in meta_tags:\n",
        "        property = tag.get(\"property\")\n",
        "        content = tag.get(\"content\")\n",
        "        # Add the property-content pair to the dictionary\n",
        "        if property and content:\n",
        "            metadata[property] = content\n",
        "\n",
        "    # Build JSON string with: url: url, metadata: metadata, text: summary text\n",
        "    # Create a dictionary\n",
        "    page = {\n",
        "        \"url\": url, # String\n",
        "        \"metadata\": metadata, # Dictionary\n",
        "        \"text\": summary # String\n",
        "    }\n",
        "    # Convert the dictionary to a JSON string\n",
        "    page_json = json.dumps(page)\n",
        "    # Convert in clear text (convert codes in text)\n",
        "    #page_json_clear_text = page_json.encode('utf-8').decode('unicode_escape')\n",
        "\n",
        "    return page_json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "pX4Rr4Lr8-2M"
      },
      "outputs": [],
      "source": [
        "# Scrape the URLs and save the results in a Python list\n",
        "\n",
        "file_path = \"/content/drive/MyDrive/colab/commons-urls-ds1\"\n",
        "#file_path = \"/content/drive/MyDrive/colab/commons-urls-test\"\n",
        "\n",
        "with open(f\"{file_path}.txt\", \"r\") as url_file:\n",
        "    data = []\n",
        "    for line in url_file:\n",
        "        url = line.strip()\n",
        "        url = url.replace(\"\\ufeff\", \"\")  # Remove BOM\n",
        "        page_json = scrape_commons_summary(url)\n",
        "        #print(page_json)\n",
        "        data.append(page_json)\n",
        "        time.sleep(1)\n",
        "\n",
        "# Save the Python list in a JSON file. File name: xxx.txt --> xxx-scs.json\n",
        "with open(f\"{file_path}-scs.json\", \"w\") as output_file:\n",
        "        json.dump(data, output_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "AXt8lI13j5JA"
      },
      "outputs": [],
      "source": [
        "# Open the JSON file to check its content (will produce an error if it's not a correctly formated JSON file)\n",
        "with open(f\"{file_path}-scs.json\", \"r\") as file:\n",
        "    data_read = json.load(file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nMRAdR5K-uQq"
      },
      "source": [
        "## Index"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sPs_aAdrL4lR"
      },
      "source": [
        "Open the JSON file and embed the items in a Chroma vector DB."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5OY-ZM_lxM-5"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade --quiet jq langchain langchain-community langchain-openai langchain-chroma langchainhub rank_bm25\n",
        "\n",
        "import jq\n",
        "from google.colab import userdata\n",
        "from langchain_community.document_loaders import JSONLoader\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain_chroma import Chroma\n",
        "from langchain import hub\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.retrievers import BM25Retriever, EnsembleRetriever\n",
        "\n",
        "OPENAI_API_KEY = userdata.get(\"OPENAI_API_KEY\")\n",
        "LANGCHAIN_API_KEY = userdata.get(\"LANGCHAIN_API_KEY\")\n",
        "%env OPENAI_API_KEY = $OPENAI_API_KEY\n",
        "%env LANGCHAIN_API_KEY = $LANGCHAIN_API_KEY\n",
        "%env LANGCHAIN_TRACING_V2 = \"true\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "PR-uONuCr7iu"
      },
      "outputs": [],
      "source": [
        "# Open the JSON file and parse/embed each item one by one\n",
        "\n",
        "file_path = \"/content/drive/MyDrive/colab/commons-urls-ds1-scs.json\"\n",
        "collection_name = \"bmae-json\"\n",
        "\n",
        "loader = JSONLoader(file_path=file_path, jq_schema=\".[]\", text_content=False)\n",
        "documents = loader.load() # Chunks (JSON item) from the JSON file\n",
        "\n",
        "embedding_model = OpenAIEmbeddings(model=\"text-embedding-3-large\") # 1536 dimensions vectors used to embed the json items and the questions\n",
        "\n",
        "vector_db = Chroma.from_documents(documents, embedding_model, collection_name=collection_name, persist_directory=\"/content/drive/MyDrive/colab/chromadb3\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ku0gOfeiro_t"
      },
      "source": [
        "## Retrieve and generate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "EmX4A5jay8WO"
      },
      "outputs": [],
      "source": [
        "# LLM chatbot with a hybrid RAG chain:\n",
        "# (To embed the question, the same model is used as for the data; the model is given in \"vector_db\".)\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-4-turbo-2024-04-09\", temperature=0.1)\n",
        "\n",
        "# Semantic search (vector retriever)\n",
        "vector_retriever = vector_db.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3}) # Chroma DB\n",
        "\n",
        "# Keyword search (bm25 retriever)\n",
        "keyword_retriever = BM25Retriever.from_documents(documents)\n",
        "keyword_retriever.k = 3\n",
        "\n",
        "# Ensemble retriever (mix of both retrivers)\n",
        "ensemble_retriever = EnsembleRetriever(retrievers=[keyword_retriever, vector_retriever], weights=[0.5, 0.5])\n",
        "\n",
        "# Download prompt template (system prompt + context (rag documents) + user question)\n",
        "prompt = hub.pull(\"dodeeric/rag-prompt-bmae\")\n",
        "\n",
        "# Take the text content of each doc, and concatenate them in one string to pass to the prompt (context)\n",
        "def format_docs_clear_text(docs):\n",
        "    return \"\\n\\n\".join(doc.page_content.encode('utf-8').decode('unicode_escape') for doc in docs)\n",
        "\n",
        "# Function to display the text content of the prompt in ai_assistant_chain\n",
        "def print_and_pass(data):\n",
        "    print(f\"Prompt content sent to the LLM: {data}\")\n",
        "    return data\n",
        "\n",
        "ai_assistant_chain = (\n",
        "    {\"context\": ensemble_retriever | format_docs_clear_text, \"question\": RunnablePassthrough()}\n",
        "    | prompt\n",
        "    #| print_and_pass\n",
        "    | llm\n",
        "    | StrOutputParser() # Convert to string\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P_Vs5q4pAiWZ"
      },
      "source": [
        "Querry the AI Assistant:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "5iMV6D16T5y8"
      },
      "outputs": [],
      "source": [
        "question = \"Pouvez-vous me montrer des portraits du roi Léopold II ?\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "djaCokNX46hX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        },
        "outputId": "835cec0e-6d31-4bb0-f5a8-cff31d5de048"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Bien sûr, voici deux portraits du roi Léopold II de Belgique :\\n\\n1. **Portrait de Léopold II, roi des Belges** - Cette chromolithographie réalisée par G. Severeyns (successeur : J.L. Goffart) en 1888 montre S.M. le roi Léopold II assis sur une chaise ornée de son monogramme brodé, surmonté d\\'une couronne royale. Ce portrait a été publié dans l\\'ouvrage \"Histoire de Belgique\" de Théodore Juste.\\n\\n   ![Léopold II](https://upload.wikimedia.org/wikipedia/commons/thumb/c/ce/L%C3%A9opold_II%2C_roi_des_Belges_-_Juste.jpg/640px-L%C3%A9opold_II%2C_roi_des_Belges_-_Juste.jpg)\\n   [Plus d\\'informations ici](https://commons.wikimedia.org/wiki/File:L%C3%A9opold_II%2C_roi_des_Belges_-_Juste.jpg)\\n\\n2. **Noces d’argent du roi Léopold II et de la reine Marie-Henriette en 1878** - Cette œuvre illustre la présentation d\\'un cadeau à la reine Marie-Henriette lors de leur vingt-cinquième anniversaire de mariage au Palais royal de Bruxelles. Le roi Léopold II est représenté en uniforme de lieutenant-général. L\\'œuvre est une gravure sur bois réalisée par Gustave Janet, d\\'après un croquis de Leo von Elliot, et gravée par Hippolyte Constant Dutheil.\\n\\n   ![Noces d’argent du roi Léopold II](https://upload.wikimedia.org/wikipedia/commons/thumb/a/a3/Noces_d%E2%80%99argent_du_roi_L%C3%A9opold_II_et_de_la_reine_Marie-Henriette_en_1878.jpg/640px-Noces_d%E2%80%99argent_du_roi_L%C3%A9opold_II_et_de_la_reine_Marie-Henriette_en_1878.jpg)\\n   [Plus d\\'informations ici](https://commons.wikimedia.org/wiki/File:Noces_d%E2%80%99argent_du_roi_L%C3%A9opold_II_et_de_la_reine_Marie-Henriette_en_1878.jpg)\\n\\nCes portraits offrent un aperçu fascinant de l\\'iconographie royale et des événements marquants de la monarchie belge à l\\'époque de Léopold II.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "ai_assistant_chain.invoke(question)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qrFCZTwc1sMU"
      },
      "outputs": [],
      "source": [
        "# Query the vector RAG only\n",
        "docs = vector_db.similarity_search(question, k=2) # List of Documents; page_content of a Document: string\n",
        "rag_context = format_docs_clear_text(docs) # One string composed of k json items\n",
        "print(rag_context)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1dyWvtg-HWbJfiRdQGTpg2TtDDzjr6R20",
      "authorship_tag": "ABX9TyOTGzwl4lztkvQvh2y1VrAQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}