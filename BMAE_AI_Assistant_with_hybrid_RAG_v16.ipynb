{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dodeeric/langchain-ai-assistant-with-hybrid-rag/blob/main/BMAE_AI_Assistant_with_hybrid_RAG_v16.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uN1I_30g_aFm"
      },
      "source": [
        "# AI Assistant (LLM Chatbot) with Hybrid RAG -- With chat history\n",
        "v1: Hybrid RAG: keyword search (bm25) and semantic search (vector db)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q6CJhAe1Xfph"
      },
      "source": [
        "v2: With memory: 1) Reformulate the question for RAG query (contextualize_q_prompt);  2) Add previous Q and A in prompt sent to the LLM."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2FGgXs38nDgM"
      },
      "source": [
        "v3: With PDF indexation"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "v5: With limited number of messages in chat history"
      ],
      "metadata": {
        "id": "cMjC6NpGxw_E"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kei890_wuANp"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade --quiet jq bs4 langchain langchain-community langchain-openai langchain-chroma langchainhub rank_bm25 pypdf\n",
        "\n",
        "import requests, json, jq, time, bs4\n",
        "from bs4 import BeautifulSoup\n",
        "from google.colab import userdata\n",
        "from langchain import hub\n",
        "from langchain_community.document_loaders import WebBaseLoader, JSONLoader, PyPDFLoader\n",
        "from langchain_community.retrievers import BM25Retriever\n",
        "from langchain.retrievers import EnsembleRetriever\n",
        "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
        "from langchain_chroma import Chroma\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "\n",
        "OPENAI_API_KEY = userdata.get(\"OPENAI_API_KEY\") # To access OpenAI LLM and embedding model via API\n",
        "LANGCHAIN_API_KEY = userdata.get(\"LANGCHAIN_API_KEY\") # To trace Langchain on Langsmith\n",
        "\n",
        "%env OPENAI_API_KEY = $OPENAI_API_KEY\n",
        "%env LANGCHAIN_API_KEY = $LANGCHAIN_API_KEY\n",
        "%env LANGCHAIN_TRACING_V2 = \"true\"\n",
        "\n",
        "# import dotenv\n",
        "# dotenv.load_dotenv()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tm_zLVsh-276"
      },
      "source": [
        "## Scrape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JQm75HI5g5e0"
      },
      "outputs": [],
      "source": [
        "# Function to scrape the text and the metadata of a web page\n",
        "\n",
        "def scrape_web_page(url):\n",
        "    \"\"\"\n",
        "    Name: swp\n",
        "    Scrape the text and the metadata of a web page\n",
        "    Input: URL of the page\n",
        "    Output: list of dictionaries with: url: url, metadata: metadata, text: text\n",
        "    \"\"\"\n",
        "\n",
        "    #filter = \"two-third last\" # balat / irpa\n",
        "    #filter = \"media-body\" # belgica / kbr\n",
        "    filter = \"hproduct commons-file-information-table\" # commons / wikimedia: summary or description section\n",
        "\n",
        "    # Get the page content\n",
        "    loader = WebBaseLoader(\n",
        "        web_paths=(url,),\n",
        "        bs_kwargs=dict(\n",
        "            parse_only=bs4.SoupStrainer(\n",
        "                class_=(filter)\n",
        "            )\n",
        "        ),\n",
        "    )\n",
        "    text = loader.load()\n",
        "    # Covert Document type into string type\n",
        "    text = text[0].page_content\n",
        "\n",
        "    # Get the metadata (open graph from Facebook, og:xxx)\n",
        "    # Get the HTML code\n",
        "    response = requests.get(url)\n",
        "    # Transform the HTML code from a Response object type into a BeautifulSoup object type to be scraped by Beautiful Soup\n",
        "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "    # Get the metadata fields\n",
        "    metadata = {} # Empty dictionary\n",
        "    # Find all the meta tags in the HTML\n",
        "    meta_tags = soup.find_all(\"meta\")\n",
        "    # Loop through the meta tags\n",
        "    for tag in meta_tags:\n",
        "        property = tag.get(\"property\")\n",
        "        content = tag.get(\"content\")\n",
        "        # Add the property-content pair to the dictionary\n",
        "        if property and content:\n",
        "            metadata[property] = content\n",
        "\n",
        "    # Build JSON string with: url: url, metadata: metadata, text: summary text\n",
        "    # Create a dictionary\n",
        "    page = {\n",
        "        \"url\": url, # String\n",
        "        \"metadata\": metadata, # Dictionary\n",
        "        \"text\": text # String\n",
        "    }\n",
        "\n",
        "    return page # Dictionary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pX4Rr4Lr8-2M"
      },
      "outputs": [],
      "source": [
        "# METHOD 1: Scrape the URLs from a file and save the results in a JSON file\n",
        "\n",
        "#ds1:\n",
        "\n",
        "file_path = \"/content/drive/MyDrive/colab/balat-urls-ds1\"\n",
        "#file_path = \"/content/drive/MyDrive/colab/belgica-urls-ds1\"\n",
        "#file_path = \"/content/drive/MyDrive/colab/commons-urls-ds1\"\n",
        "\n",
        "#ds2:\n",
        "#file_path = \"/content/drive/MyDrive/colab/balat-urls-ds2\"\n",
        "#file_path = \"/content/drive/MyDrive/colab/commons-urls-ds2\"\n",
        "\n",
        "with open(f\"{file_path}.txt\", \"r\") as urls_file:\n",
        "    items = []\n",
        "    for line in urls_file:\n",
        "        url = line.strip() # Remove spaces at the beginning and at the end of the string\n",
        "        url = url.replace(\"\\ufeff\", \"\")  # Remove BOM (Byte order mark at the start of a text stream)\n",
        "        item = scrape_web_page(url)\n",
        "        print(item)\n",
        "        items.append(item)\n",
        "        #time.sleep(1)\n",
        "\n",
        "# Save the Python list in a JSON file\n",
        "# json.dump is designed to take the Python objects, not the already-JSONified string. Read docs.python.org/3/library/json.html.\n",
        "with open(f\"{file_path}-swp.json\", \"w\") as json_file:\n",
        "    json.dump(items, json_file) # That step replaces the accentuated characters (ex: é) by its utf8 codes (ex: \\u00e9)\n",
        "json_file.close()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# METHOD 2: For Belgica: Scrape the URLs automatically generated and save the results in a JSON file\n",
        "\n",
        "file_path = \"/content/drive/MyDrive/colab/belgica-\"\n",
        "\n",
        "items = []\n",
        "\n",
        "number1 = 10000101\n",
        "step = 100\n",
        "number2 = number1 + step\n",
        "\n",
        "for number in range(number1, number2):\n",
        "    url = f\"https://opac.kbr.be/LIBRARY/doc/SYRACUSE/{number}\"\n",
        "    #print(url)\n",
        "    item = scrape_web_page(url)\n",
        "    print(item)\n",
        "    if item[\"text\"]:\n",
        "        items.append(item)\n",
        "        print(\"saved\")\n",
        "    #time.sleep(1)\n",
        "\n",
        "# Save the Python list in a JSON file\n",
        "# json.dump is designed to take the Python objects, not the already-JSONified string. Read docs.python.org/3/library/json.html.\n",
        "with open(f\"{file_path}-{number1}-{number2}-swp.json\", \"w\") as json_file:\n",
        "    json.dump(items, json_file) # That step replaces the accentuated characters (ex: é) by its utf8 codes (ex: \\u00e9)\n",
        "json_file.close()"
      ],
      "metadata": {
        "id": "NdwxOiNwIDf9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# METHOD 3: For Commons: Scrape the URLs from a Commons Category and save the results in a JSON file\n",
        "\n",
        "file_path = \"/content/drive/MyDrive/colab/commons-\"\n",
        "\n",
        "category = \"Category:Engravings_by_Dodeeric\"\n",
        "\n",
        "items = []\n",
        "href_old = \"\"\n",
        "\n",
        "# Step 1: Load the HTML content from a webpage\n",
        "url = f\"https://commons.wikimedia.org/wiki/{category}\"\n",
        "response = requests.get(url)\n",
        "html_content = response.text\n",
        "\n",
        "# Step 2: Parse the HTML content\n",
        "soup = BeautifulSoup(html_content, 'html.parser')\n",
        "\n",
        "# Step 3: Find all URLs in <a> tags\n",
        "urls = []\n",
        "for link in soup.find_all('a'):\n",
        "    href = link.get('href')\n",
        "    if href:\n",
        "        #print(href)\n",
        "        if href.startswith(\"/wiki/File:\") and href != href_old: # This test because all links are in double!\n",
        "            urls.append(f\"https://commons.wikimedia.org{href}\")\n",
        "            href_old = href\n",
        "\n",
        "#print(\"***********************************************************\")\n",
        "# Print all found URLs\n",
        "#for url in urls:\n",
        "#    print(url)\n",
        "#print(\"***********************************************************\")\n",
        "\n",
        "number_of_pages = len(urls)\n",
        "print(f\"Number of pages to scrape: {number_of_pages}\")\n",
        "\n",
        "i = 1\n",
        "items = []\n",
        "for url in urls:\n",
        "    print(f\"{i}/{number_of_pages}\")\n",
        "    url = url.replace(\"\\ufeff\", \"\")  # Remove BOM (Byte order mark at the start of a text stream)\n",
        "    item = scrape_web_page(url)\n",
        "    print(item)\n",
        "    items.append(item)\n",
        "    #time.sleep(1)\n",
        "    i = i + 1\n",
        "\n",
        "# Save the Python list in a JSON file\n",
        "# json.dump is designed to take the Python objects, not the already-JSONified string. Read docs.python.org/3/library/json.html.\n",
        "with open(f\"{file_path}{category}-swp.json\", \"w\") as json_file:\n",
        "    json.dump(items, json_file) # That step replaces the accentuated characters (ex: é) by its utf8 codes (ex: \\u00e9)\n",
        "json_file.close()"
      ],
      "metadata": {
        "id": "Fp9Kn92GaQ_s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AXt8lI13j5JA"
      },
      "outputs": [],
      "source": [
        "# Open the JSON file to check its content (will produce an error if it's not a correctly formated JSON file)\n",
        "with open(f\"{file_path}-swp.json\", \"r\") as input_file:\n",
        "    items_read = json.load(input_file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nMRAdR5K-uQq"
      },
      "source": [
        "## Index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PR-uONuCr7iu"
      },
      "outputs": [],
      "source": [
        "# Open the JSON files and load each JSON item one by one in the \"documents\" variable (type: Document)\n",
        "\n",
        "file_path1 = \"/content/drive/MyDrive/colab/commons-urls-ds1-swp.json\"\n",
        "file_path2 = \"/content/drive/MyDrive/colab/balat-urls-ds1-swp.json\"\n",
        "file_path3 = \"/content/drive/MyDrive/colab/belgica-urls-ds1-swp.json\"\n",
        "file_path4 = \"/content/drive/MyDrive/colab/commons-urls-ds2-swp.json\"\n",
        "file_path5 = \"/content/drive/MyDrive/colab/balat-urls-ds2-swp.json\"\n",
        "file_paths = [file_path1, file_path2, file_path3, file_path4, file_path5]\n",
        "\n",
        "documents = []\n",
        "for file_path in file_paths:\n",
        "    loader = JSONLoader(file_path=file_path, jq_schema=\".[]\", text_content=False)\n",
        "    docs = loader.load() # Chunks (JSON items) from the JSON files; list of Documents\n",
        "    documents = documents + docs # This variable contents all the JSON items"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FStUm9RgGy4J"
      },
      "outputs": [],
      "source": [
        "# Open the PDF files and load each page one by one in the \"documents\" variable (type: Document)\n",
        "\n",
        "file_path1 = \"/content/drive/MyDrive/colab/cdf-fxw.pdf\"\n",
        "file_paths = [file_path1]\n",
        "\n",
        "for file_path in file_paths:\n",
        "    loader = PyPDFLoader(file_path)\n",
        "    pages = loader.load_and_split() # 1 pdf page per chunk\n",
        "    documents = documents + pages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K2kNvVf1VVQ7"
      },
      "source": [
        "Run step 1 or step 2:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WtSS9Dz2Qkwn"
      },
      "outputs": [],
      "source": [
        "# STEP 1: Instanciate a Chroma DB and load the data from disk.\n",
        "collection_name = \"bmae\"\n",
        "embedding_model = OpenAIEmbeddings(model=\"text-embedding-3-large\") # 3072 dimensions vectors used to embed the chunks and the questions\n",
        "vector_db = Chroma(embedding_function=embedding_model, collection_name=collection_name, persist_directory=\"/content/drive/MyDrive/colab/chromadb\")\n",
        "docs = vector_db.get()\n",
        "documents= docs[\"documents\"]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(documents)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QI75xAXPvcPP",
        "outputId": "0d3849fd-20b7-421f-f89d-8ee3e32823fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "documents[7]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "id": "OI-g4jM-ySUo",
        "outputId": "44ef5a11-2297-4a6b-d6bb-4298a8792d40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'{\"url\": \"https://commons.wikimedia.org/wiki/File:Prestation_de_serment_de_L%C3%A9opold_II_le_17_d%C3%A9cembre_1865.jpg\", \"metadata\": {\"og:image\": \"https://upload.wikimedia.org/wikipedia/commons/thumb/6/64/Prestation_de_serment_de_L%C3%A9opold_II_le_17_d%C3%A9cembre_1865.jpg/640px-Prestation_de_serment_de_L%C3%A9opold_II_le_17_d%C3%A9cembre_1865.jpg\", \"og:image:width\": \"640\", \"og:image:height\": \"974\", \"og:title\": \"File:Prestation de serment de L\\\\u00e9opold II le 17 d\\\\u00e9cembre 1865.jpg - Wikimedia Commons\", \"og:type\": \"website\"}, \"text\": \"\\\\n\\\\n\\\\nDescriptionPrestation de serment de L\\\\u00e9opold II le 17 d\\\\u00e9cembre 1865.jpg\\\\n\\\\nEnglish:  Oath-taking of Leopold\\\\u00a0II of Belgium, Palace of the Nation (Brussels), 17 December 1865.\\\\nFran\\\\u00e7ais\\\\u00a0:  Prestation de serment de L\\\\u00e9opold\\\\u00a0II de Belgique, Palais de la Nation (Bruxelles), le 17 d\\\\u00e9cembre 1865.\\\\nNederlands:  Be\\\\u00ebdiging van Leopold\\\\u00a0II van Belgi\\\\u00eb, Palais de la Nation (Brussel), 17 december 1865.\\\\nDeutsch:  Vereidigung von Leopold\\\\u00a0II von Belgien, Palais de la Nation (Br\\\\u00fcssel), 17. Dezember 1865.\\\\n\\\\n\\\\nDate\\\\n\\\\ncirca 1865date QS:P,+1865-00-00T00:00:00Z/9,P1480,Q5727902\\\\n\\\\n\\\\nSource\\\\n\\\\nOwn work\\\\n\\\\n\\\\nAuthor\\\\n\\\\nUnknown authorUnknown authorAfter (photo):\\\\n\\\\n\\\\n\\\\nGh\\\\u00e9mar Fr\\\\u00e8res studio\\\\n\\\\u00a0(fl. 1882)\\\\u00a0\\\\u00a0 \\\\u00a0\\\\n\\\\n\\\\nAlternative names\\\\n\\\\nGhemar Fr\\\\u00e8res Atelier de Photographie\\\\n\\\\nDescription\\\\nBelgianGh\\\\u00e9mar Fr\\\\u00e8res, Photographes du Roi, 27, Rue de l\\'Ecuyer, Bruxelles.\\\\nEnglish:  The photo studio of the two brothers Gh\\\\u00e9mar was the most renowned Belgian photostudio in the period 1855\\\\u20131870. \\\\nIn 1855 Louis Gh\\\\u00e9mar (1820\\\\u20131873)[1] opened a photostudio in Brussels, next to the studio of Jules G\\\\u00e9ruzet. \\\\nIn the beginning Louis Gh\\\\u00e9mar worked together with Robert S\\\\u00e9v\\\\u00e9rin. S\\\\u00e9v\\\\u00e9rin took the photos and Gh\\\\u00e9mar made the retouches and eventually colours the photos. But S\\\\u00e9v\\\\u00e9rin left Brussels and was replaced by Louis Gh\\\\u00e9mars halfbrother, L\\\\u00e9on Auverlaux. From then on the name of the studio was changed to Gh\\\\u00e9mar Fr\\\\u00e8res. \\\\n\\\\nLouis Gh\\\\u00e9mar died in 1873 but the studio kept the name Gh\\\\u00e9mar Fr\\\\u00e8res until 1894 when G\\\\u00e9ruzet takes over the studio, including all the negatives of Gh\\\\u00e9mar.[2]\\\\n\\\\nWork period\\\\nbetween 1855 and 1894date QS:P,+1850-00-00T00:00:00Z/7,P1319,+1855-00-00T00:00:00Z/9,P1326,+1894-00-00T00:00:00Z/9\\\\n\\\\nWork location\\\\n\\\\nCity of Brussels\\\\n\\\\nAuthority file\\\\n\\\\n: Q21557453\\\\nVIAF:\\\\u2009158671009\\\\nLCCN:\\\\u2009no2007070950\\\\nBNF:\\\\u200915346099j\\\\nRKD:\\\\u2009417254\\\\nWorldCat\\\\n\\\\n\\\\n\\\\ncreator QS:P170,Q21557453\\\\n\\\\n\\\\nOther versions\\\\n\\\\n\\\\n\\\\n\\\\nFile:Prestation de serment de L\\\\u00e9opold II.jpg\\\\nPhotographie de Gh\\\\u00e9mar Fr\\\\u00e8res, retouch\\\\u00e9e \\\\u00e0 la gouache, utilis\\\\u00e9e pour r\\\\u00e9aliser la chromolithographie. / Photograph of Gh\\\\u00e9mar Fr\\\\u00e8res, enhanced with gouache, copied to realise the chromolithograph.\\\\n\\\\n\\\\n\\\\nTechniqueInfoFieldchromolithographmedium QS:P186,Q1121337\\\\n\\\\nSizeInfoFieldheight: 23 cm (9 in); width: 15 cm (5.9 in)dimensions QS:P2048,23U174728dimensions QS:P2049,15U174728\\\\n\\\\nInscriptionsInfoFieldUnsigned\\\\n\\\\nOriginal captionInfoFieldNone\\\\n\\\\nScanned byInfoField\\\\u00c9ric Dod\\\\u00e9mont (Dodeeric)\\\\n\\\\n\\\\n\"}'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hjedA55QYeNS"
      },
      "outputs": [],
      "source": [
        "# STEP 2: ONLY TO EMBED! Instantiate a Chroma DB, embed the JSON items (documents), then save to disk.\n",
        "collection_name = \"bmae\"\n",
        "embedding_model = OpenAIEmbeddings(model=\"text-embedding-3-large\") # 3072 dimensions vectors used to embed the chunks and the questions\n",
        "vector_db = Chroma.from_documents(documents, embedding_model, collection_name=collection_name, persist_directory=\"/content/drive/MyDrive/colab/chromadb\")\n",
        "# To check the Chroma vector db (sqlite3):\n",
        "# $ sqlite3 chroma.sqlite3\n",
        "# sqlite> .tables ===> List of the tables\n",
        "# sqlite> select * from collections; ===> Name of the collection & size of the vectors\n",
        "# sqlite> select * from embeddings; ===> Number of records in the db\n",
        "# sqlite> select * from embedding_metadata; ===> Display json items"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ku0gOfeiro_t"
      },
      "source": [
        "## Retrieve and generate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EmX4A5jay8WO"
      },
      "outputs": [],
      "source": [
        "# LLM chatbot with a hybrid RAG chain:\n",
        "# (To embed the question, the same model is used as for the data; the model is given in \"vector_db\".)\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-4-turbo-2024-04-09\", temperature=0)\n",
        "\n",
        "# Semantic search (vector retriever)\n",
        "vector_retriever = vector_db.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3}) # Chroma DB\n",
        "\n",
        "# Keyword search (bm25 retriever)\n",
        "keyword_retriever = BM25Retriever.from_documents(documents)\n",
        "keyword_retriever.k = 3\n",
        "\n",
        "# Ensemble retriever (mix of both retrivers) -- Weights = order of the results!!! [1,0] means: all bm25 first, all vector after...\n",
        "ensemble_retriever = EnsembleRetriever(retrievers=[keyword_retriever, vector_retriever], weights=[0.5, 0.5])\n",
        "\n",
        "\"\"\"\n",
        "# Without memory:\n",
        "\n",
        "# Download prompt template: system prompt + inputs (rag_output + chat_history + question)\n",
        "prompt = hub.pull(\"dodeeric/rag-prompt-bmae-with-history\")\n",
        "\n",
        "# Take the text content of each doc, and concatenate them in one string to pass to the prompt (context)\n",
        "def format_docs_clear_text(docs):\n",
        "    return \"\\n\\n\".join(doc.page_content.encode('utf-8').decode('unicode_escape') for doc in docs)\n",
        "\n",
        "# Function to display the text content of the prompt in ai_assistant_chain\n",
        "def print_and_pass(data):\n",
        "    print(f\"Prompt content sent to the LLM: {data}\")\n",
        "    return data\n",
        "\n",
        "# Langchain chain: the LLM chatbot with hybrid RAG. Type: RunnableSequence (chain) -- How/where is the question pass to the RAG??? In LangSmith, we can see the input (question) of the 3 retreivers\n",
        "ai_assistant_chain = ({\"rag_output\": ensemble_retriever | format_docs_clear_text, \"chat_history\": RunnablePassthrough(), \"question\": RunnablePassthrough()}\n",
        "    | prompt\n",
        "    #| print_and_pass\n",
        "    | llm\n",
        "    | StrOutputParser() # Convert to string\n",
        ")\n",
        "\"\"\"\n",
        "\n",
        "from langchain.chains import create_history_aware_retriever\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "from langchain.chains import create_retrieval_chain\n",
        "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
        "from langchain_core.messages import HumanMessage, AIMessage\n",
        "\n",
        "from langchain.memory import ConversationBufferWindowMemory\n",
        "\n",
        "chat_history = []\n",
        "chat_history2 = ConversationBufferWindowMemory(k=2, return_messages=True)\n",
        "\n",
        "contextualize_q_system_prompt = \"\"\"\n",
        "Given a chat history and the latest user question \\\n",
        "which might reference context in the chat history, formulate a standalone question \\\n",
        "which can be understood without the chat history. Do NOT answer the question, \\\n",
        "just reformulate it if needed and otherwise return it as is.\n",
        "\"\"\"\n",
        "\n",
        "contextualize_q_prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", contextualize_q_system_prompt),\n",
        "        MessagesPlaceholder(\"chat_history\"),\n",
        "        (\"human\", \"{input}\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "history_aware_retriever = create_history_aware_retriever(\n",
        "    llm, ensemble_retriever, contextualize_q_prompt\n",
        ")\n",
        "\n",
        "qa_system_prompt = \"\"\"\n",
        "You are an artwork specialist. You must assist the users in finding, describing, and displaying artworks related to the Belgian monarchy. \\\n",
        "You first have to search answers in the \"Knowledge Base\". If no answers are found in the \"Knowledge Base\", then answer with your own knowledge. \\\n",
        "You have to answer in the same language as the question.\n",
        "At the end of the answer:\n",
        "- give a link to a web page about the artwork (see the \"url\" field).\n",
        "- display an image of the artwork (see the \"og:image\" field).\n",
        "\n",
        "Knowledge Base:\n",
        "\n",
        "{context}\n",
        "\"\"\"\n",
        "\n",
        "qa_prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", qa_system_prompt),\n",
        "        MessagesPlaceholder(\"chat_history\"),\n",
        "        (\"human\", \"{input}\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "question_answer_chain = create_stuff_documents_chain(llm, qa_prompt)\n",
        "\n",
        "ai_assistant_chain = create_retrieval_chain(history_aware_retriever, question_answer_chain)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P_Vs5q4pAiWZ"
      },
      "source": [
        "Query the AI Assistant:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5iMV6D16T5y8"
      },
      "outputs": [],
      "source": [
        "question = \"Pouvez-vous me montrer le tableau 'La revue des écoles' ?\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rkeT6gTMlpZ9"
      },
      "outputs": [],
      "source": [
        "question = \"Qui a peint ce tableau ?\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LESYfyp0rs4V"
      },
      "outputs": [],
      "source": [
        "question = \"Quelle est la dimension du tableau ?\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nqH2WKWeaqO5"
      },
      "outputs": [],
      "source": [
        "question = \"Pouvez-vous me montrer un tableau de Charles Porion ?\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MM_Wj8zvb8UR"
      },
      "outputs": [],
      "source": [
        "question = \"Quel est la date de naissance du peintre ?\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wu7YZfAYE-CZ"
      },
      "outputs": [],
      "source": [
        "question = \"Camille Van Camp a-t-il fait des croquis pour sa peinture 'La fête patriotique ' ?\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TVCnHqzq0jhQ"
      },
      "outputs": [],
      "source": [
        "#answer = ai_assistant_chain.invoke(question) # Without memory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "djaCokNX46hX"
      },
      "outputs": [],
      "source": [
        "output = ai_assistant_chain.invoke({\"input\": question, \"chat_history\": chat_history}) # output is a dictionary. output[\"answer\"] is in markdown format."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ha7DuSyBxBkQ",
        "outputId": "61d355d6-0179-45d5-ba3d-a468857d1ef9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Le tableau \"La revue des écoles en 1878\" de Jan Verhas mesure 241 cm de hauteur et 432 cm de largeur. Cette grande toile monumentale est exposée aux Musées royaux des Beaux-Arts de Belgique.\n"
          ]
        }
      ],
      "source": [
        "print(output[\"answer\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nS3uFmchgR8U"
      },
      "outputs": [],
      "source": [
        "#chat_history.extend([HumanMessage(content=question), output[\"answer\"]])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#chat_history.extend([question, output[\"answer\"]])"
      ],
      "metadata": {
        "id": "uKYcTo1FypaO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat_history2.save_context({\"input\": question}, {\"output\": output[\"answer\"]})"
      ],
      "metadata": {
        "id": "wMoIBNU6zkbN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "load_memory = chat_history2.load_memory_variables({})"
      ],
      "metadata": {
        "id": "FpFxlJf70tBW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat_history = load_memory[\"history\"]"
      ],
      "metadata": {
        "id": "j63rA40f1PqX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6O1cK9VlxO05",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a29ab16-caaf-47f7-fee5-df1f1f0e854c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[HumanMessage(content=\"Pouvez-vous me montrer le tableau 'La revue des écoles' ?\"), AIMessage(content='Le tableau \"La revue des écoles en 1878\" de Jan Verhas est une œuvre importante qui capture un événement marquant de l\\'histoire belge. Réalisée en 1880, cette peinture illustre le défilé de 23.000 élèves des écoles bruxelloises devant le roi Léopold II et la reine Marie-Henriette à l\\'occasion de leurs noces d\\'argent. L\\'événement a eu lieu le 22 août 1878 sur la place des Palais à Bruxelles. Cette œuvre est célèbre pour sa représentation détaillée et vivante de la parade, mettant en avant l\\'importance de l\\'éducation et la jeunesse dans la société belge de l\\'époque.\\n\\nPour plus d\\'informations sur ce tableau, vous pouvez visiter la page suivante : [La revue des écoles en 1878](https://commons.wikimedia.org/wiki/File:Jan_Verhas_(1834-1896)_Optocht_van_de_scholen_in_1878_-_Old_Masters_Museum_Brussel_30-4-2017_11-18-20.JPG)\\n\\n![La revue des écoles en 1878](https://upload.wikimedia.org/wikipedia/commons/thumb/5/5a/Jan_Verhas_%281834-1896%29_Optocht_van_de_scholen_in_1878_-_Old_Masters_Museum_Brussel_30-4-2017_11-18-20.JPG/640px-Jan_Verhas_%281834-1896%29_Optocht_van_de_scholen_in_1878_-_Old_Masters_Museum_Brussel_30-4-2017_11-18-20.JPG)'), HumanMessage(content='Qui a peint ce tableau ?'), AIMessage(content='Le tableau \"La revue des écoles en 1878\" a été peint par Jan Verhas, un peintre belge né en 1834 et décédé en 1896. Jan Verhas était spécialisé dans la peinture de genre et est connu pour ses représentations détaillées de la vie sociale et des événements importants en Belgique. Son œuvre \"La revue des écoles en 1878\" est particulièrement célèbre pour sa représentation vivante et détaillée d\\'un événement marquant impliquant la monarchie belge.\\n\\nPour plus d\\'informations sur ce tableau, vous pouvez visiter la page suivante : [La revue des écoles en 1878](https://commons.wikimedia.org/wiki/File:Jan_Verhas_(1834-1896)_Optocht_van_de_scholen_in_1878_-_Old_Masters_Museum_Brussel_30-4-2017_11-18-20.JPG)\\n\\n![La revue des écoles en 1878](https://upload.wikimedia.org/wikipedia/commons/thumb/5/5a/Jan_Verhas_%281834-1896%29_Optocht_van_de_scholen_in_1878_-_Old_Masters_Museum_Brussel_30-4-2017_11-18-20.JPG/640px-Jan_Verhas_%281834-1896%29_Optocht_van_de_scholen_in_1878_-_Old_Masters_Museum_Brussel_30-4-2017_11-18-20.JPG)')]\n"
          ]
        }
      ],
      "source": [
        "print(chat_history)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat_history3"
      ],
      "metadata": {
        "id": "EFP6v0J2zwPr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qrFCZTwc1sMU"
      },
      "outputs": [],
      "source": [
        "# Query the vector RAG only\n",
        "docs = vector_db.similarity_search(question, k=2) # List of Documents; page_content of a Document: string\n",
        "print(docs)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tests"
      ],
      "metadata": {
        "id": "6u5JHCm4-0fV"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XZG7BBRxEBb4"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1_oNoMqmvoe6QWU7rBAgFyouJfMeuaBib",
      "authorship_tag": "ABX9TyP4qMYu4ZqiGYQH9d8JsOc/",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}