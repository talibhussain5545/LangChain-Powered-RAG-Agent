{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dodeeric/langchain-ai-assistant-with-hybrid-rag/blob/main/BMAE_AI_Assistant_with_hybrid_RAG_v13.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uN1I_30g_aFm"
      },
      "source": [
        "# AI Assistant (LLM Chatbot) with Hybrid RAG -- With chat history\n",
        "v1: Hybrid RAG: keyword search (bm25) and semantic search (vector db)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "v2: With memory: 1) Reformulate the question for RAG query (contextualize_q_prompt);  2) Add previous Q and A in prompt sent to the LLM."
      ],
      "metadata": {
        "id": "Q6CJhAe1Xfph"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "v3: With PDF indexation"
      ],
      "metadata": {
        "id": "2FGgXs38nDgM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kei890_wuANp"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade --quiet jq bs4 langchain langchain-community langchain-openai langchain-chroma langchainhub rank_bm25 pypdf\n",
        "\n",
        "import requests, json, jq, time, bs4\n",
        "from bs4 import BeautifulSoup\n",
        "from google.colab import userdata\n",
        "from langchain import hub\n",
        "from langchain_community.document_loaders import WebBaseLoader, JSONLoader, PyPDFLoader\n",
        "from langchain_community.retrievers import BM25Retriever\n",
        "from langchain.retrievers import EnsembleRetriever\n",
        "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
        "from langchain_chroma import Chroma\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "\n",
        "OPENAI_API_KEY = userdata.get(\"OPENAI_API_KEY\") # To access OpenAI LLM and embedding model via API\n",
        "LANGCHAIN_API_KEY = userdata.get(\"LANGCHAIN_API_KEY\") # To trace Langchain on Langsmith\n",
        "\n",
        "%env OPENAI_API_KEY = $OPENAI_API_KEY\n",
        "%env LANGCHAIN_API_KEY = $LANGCHAIN_API_KEY\n",
        "%env LANGCHAIN_TRACING_V2 = \"true\"\n",
        "\n",
        "# import dotenv\n",
        "# dotenv.load_dotenv()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tm_zLVsh-276"
      },
      "source": [
        "## Scrape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JQm75HI5g5e0"
      },
      "outputs": [],
      "source": [
        "# Function to scrape the text and the metadata of a web page\n",
        "\n",
        "def scrape_web_page(url):\n",
        "    \"\"\"\n",
        "    Name: swp\n",
        "    Scrape the text and the metadata of a web page\n",
        "    Input: URL of the page\n",
        "    Output: list of dictionaries with: url: url, metadata: metadata, text: text\n",
        "    \"\"\"\n",
        "\n",
        "    filter = \"two-third last\" # balat / irpa\n",
        "    #filter = \"notice_corps media\" #  belgica / kbr\n",
        "    #filter = \"hproduct commons-file-information-table\" # commons / wikimedia: summary or description section\n",
        "\n",
        "    # Get the page content\n",
        "    loader = WebBaseLoader(\n",
        "        web_paths=(url,),\n",
        "        bs_kwargs=dict(\n",
        "            parse_only=bs4.SoupStrainer(\n",
        "                class_=(filter)\n",
        "            )\n",
        "        ),\n",
        "    )\n",
        "    text = loader.load()\n",
        "    # Covert Document type into string type\n",
        "    text = text[0].page_content\n",
        "\n",
        "    # Get the metadata (open graph from Facebook, og:xxx)\n",
        "    # Get the HTML code\n",
        "    response = requests.get(url)\n",
        "    # Transform the HTML code from a Response object type into a BeautifulSoup object type to be scraped by Beautiful Soup\n",
        "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "    # Get the metadata fields\n",
        "    metadata = {} # Empty dictionary\n",
        "    # Find all the meta tags in the HTML\n",
        "    meta_tags = soup.find_all(\"meta\")\n",
        "    # Loop through the meta tags\n",
        "    for tag in meta_tags:\n",
        "        property = tag.get(\"property\")\n",
        "        content = tag.get(\"content\")\n",
        "        # Add the property-content pair to the dictionary\n",
        "        if property and content:\n",
        "            metadata[property] = content\n",
        "\n",
        "    # Build JSON string with: url: url, metadata: metadata, text: summary text\n",
        "    # Create a dictionary\n",
        "    page = {\n",
        "        \"url\": url, # String\n",
        "        \"metadata\": metadata, # Dictionary\n",
        "        \"text\": text # String\n",
        "    }\n",
        "\n",
        "    return page # Dictionary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pX4Rr4Lr8-2M"
      },
      "outputs": [],
      "source": [
        "# Scrape the URLs and save the results in a JSON file\n",
        "\n",
        "#ds1:\n",
        "\n",
        "#file_path = \"/content/drive/MyDrive/colab/balat-urls-ds2\" # apyfy wcc used instead\n",
        "#file_path = \"/content/drive/MyDrive/colab/belgica-urls-ds2\" # apyfy wcc used instead\n",
        "#file_path = \"/content/drive/MyDrive/colab/commons-urls-ds2\"\n",
        "\n",
        "#ds2:\n",
        "#file_path = \"/content/drive/MyDrive/colab/balat-urls-ds2\"\n",
        "#file_path = \"/content/drive/MyDrive/colab/commons-urls-ds2\"\n",
        "\n",
        "#ds-test:\n",
        "#file_path = \"/content/drive/MyDrive/colab/commons-urls-test\"\n",
        "#file_path = \"/content/drive/MyDrive/colab/balat-urls-test\"\n",
        "#file_path = \"/content/drive/MyDrive/colab/belgica-urls-test\"\n",
        "\n",
        "with open(f\"{file_path}.txt\", \"r\") as urls_file:\n",
        "    items = []\n",
        "    for line in urls_file:\n",
        "        url = line.strip()\n",
        "        url = url.replace(\"\\ufeff\", \"\")  # Remove BOM\n",
        "        item = scrape_web_page(url)\n",
        "        print(item)\n",
        "        items.append(item)\n",
        "        #time.sleep(1)\n",
        "\n",
        "# Save the Python list in a JSON file\n",
        "# json.dump is designed to take the Python objects, not the already-JSONified string. Read docs.python.org/3/library/json.html.\n",
        "with open(f\"{file_path}-swp.json\", \"w\") as json_file:\n",
        "    json.dump(items, json_file) # Replaces the accentuated characters (ex: Ã©) by its utf8 codes (ex: \\u00e9)\n",
        "json_file.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AXt8lI13j5JA"
      },
      "outputs": [],
      "source": [
        "# Open the JSON file to check its content (will produce an error if it's not a correctly formated JSON file)\n",
        "with open(f\"{file_path}-swp.json\", \"r\") as input_file:\n",
        "    items_read = json.load(input_file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nMRAdR5K-uQq"
      },
      "source": [
        "## Index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PR-uONuCr7iu"
      },
      "outputs": [],
      "source": [
        "# Open the JSON files and load each JSON item one by one in the \"documents\" variable (type: Document)\n",
        "\n",
        "file_path1 = \"/content/drive/MyDrive/colab/commons-urls-ds1-swp.json\"\n",
        "file_path2 = \"/content/drive/MyDrive/colab/balat-ds1c-wcc-cheerio-ex_2024-04-06_09-05-15-262.json\"\n",
        "file_path3 = \"/content/drive/MyDrive/colab/belgica-ds1c-wcc-cheerio-ex_2024-04-06_08-30-26-786.json\"\n",
        "file_path4 = \"/content/drive/MyDrive/colab/commons-urls-ds2-swp.json\"\n",
        "file_path5 = \"/content/drive/MyDrive/colab/balat-urls-ds2-swp.json\"\n",
        "file_paths = [file_path1, file_path2, file_path3, file_path4, file_path5]\n",
        "\n",
        "documents = []\n",
        "for file_path in file_paths:\n",
        "    loader = JSONLoader(file_path=file_path, jq_schema=\".[]\", text_content=False)\n",
        "    docs = loader.load() # Chunks (JSON items) from the JSON files; list of Documents\n",
        "    documents = documents + docs # This variable contents all the JSON items"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Open the PDF files and load each page one by one in the \"documents\" variable (type: Document)\n",
        "\n",
        "file_path1 = \"/content/drive/MyDrive/colab/BPEB31_DOS4_42-55_FR_LR.pdf\"\n",
        "file_path2 = \"/content/drive/MyDrive/colab/MD-vol1-2-3.pdf\"\n",
        "file_paths = [file_path1, file_path2]\n",
        "\n",
        "for file_path in file_paths:\n",
        "    loader = PyPDFLoader(file_path)\n",
        "    pages = loader.load_and_split() # 1 pdf page per chunk\n",
        "    documents = documents + pages"
      ],
      "metadata": {
        "id": "FStUm9RgGy4J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "documents[2100].metadata"
      ],
      "metadata": {
        "id": "1TQbQmSciMLU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run step 1 or step 2:"
      ],
      "metadata": {
        "id": "K2kNvVf1VVQ7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 1: Instanciate a Chroma DB and load the data from disk.\n",
        "collection_name = \"bmae-json\"\n",
        "embedding_model = OpenAIEmbeddings(model=\"text-embedding-3-large\") # 3072 dimensions vectors used to embed the chunks and the questions\n",
        "vector_db = Chroma(embedding_function=embedding_model, collection_name=collection_name, persist_directory=\"/content/drive/MyDrive/colab/chromadb2\")"
      ],
      "metadata": {
        "id": "WtSS9Dz2Qkwn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hjedA55QYeNS"
      },
      "outputs": [],
      "source": [
        "# STEP 2: ONLY TO EMBED! Instantiate a Chroma DB, embed the JSON items (documents), then save to disk.\n",
        "collection_name = \"bmae-json\"\n",
        "embedding_model = OpenAIEmbeddings(model=\"text-embedding-3-large\") # 3072 dimensions vectors used to embed the chunks and the questions\n",
        "vector_db = Chroma.from_documents(documents, embedding_model, collection_name=collection_name, persist_directory=\"/content/drive/MyDrive/colab/chromadb2\")\n",
        "# To check the Chroma vector db (sqlite3):\n",
        "# $ sqlite3 chroma.sqlite3\n",
        "# sqlite> .tables ===> List of the tables\n",
        "# sqlite> select * from collections; ===> Name of the collection & size of the vectors\n",
        "# sqlite> select * from embeddings; ===> Number of records in the db\n",
        "# sqlite> select * from embedding_metadata; ===> Display json items"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ku0gOfeiro_t"
      },
      "source": [
        "## Retrieve and generate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EmX4A5jay8WO"
      },
      "outputs": [],
      "source": [
        "# LLM chatbot with a hybrid RAG chain:\n",
        "# (To embed the question, the same model is used as for the data; the model is given in \"vector_db\".)\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-4-turbo-2024-04-09\", temperature=0)\n",
        "\n",
        "# Semantic search (vector retriever)\n",
        "vector_retriever = vector_db.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3}) # Chroma DB\n",
        "\n",
        "# Keyword search (bm25 retriever)\n",
        "keyword_retriever = BM25Retriever.from_documents(documents)\n",
        "keyword_retriever.k = 3\n",
        "\n",
        "# Ensemble retriever (mix of both retrivers) -- Weights = order of the results!!! [1,0] means: all bm25 first, all vector after...\n",
        "ensemble_retriever = EnsembleRetriever(retrievers=[keyword_retriever, vector_retriever], weights=[0.5, 0.5])\n",
        "\n",
        "\"\"\"\n",
        "# Without memory:\n",
        "\n",
        "# Download prompt template: system prompt + inputs (rag_output + chat_history + question)\n",
        "prompt = hub.pull(\"dodeeric/rag-prompt-bmae-with-history\")\n",
        "\n",
        "# Take the text content of each doc, and concatenate them in one string to pass to the prompt (context)\n",
        "def format_docs_clear_text(docs):\n",
        "    return \"\\n\\n\".join(doc.page_content.encode('utf-8').decode('unicode_escape') for doc in docs)\n",
        "\n",
        "# Function to display the text content of the prompt in ai_assistant_chain\n",
        "def print_and_pass(data):\n",
        "    print(f\"Prompt content sent to the LLM: {data}\")\n",
        "    return data\n",
        "\n",
        "# Langchain chain: the LLM chatbot with hybrid RAG. Type: RunnableSequence (chain) -- How/where is the question pass to the RAG??? In LangSmith, we can see the input (question) of the 3 retreivers\n",
        "ai_assistant_chain = ({\"rag_output\": ensemble_retriever | format_docs_clear_text, \"chat_history\": RunnablePassthrough(), \"question\": RunnablePassthrough()}\n",
        "    | prompt\n",
        "    #| print_and_pass\n",
        "    | llm\n",
        "    | StrOutputParser() # Convert to string\n",
        ")\n",
        "\"\"\"\n",
        "\n",
        "from langchain.chains import create_history_aware_retriever\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "from langchain.chains import create_retrieval_chain\n",
        "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
        "from langchain_core.messages import HumanMessage\n",
        "\n",
        "chat_history = []\n",
        "\n",
        "contextualize_q_system_prompt = \"\"\"\n",
        "Given a chat history and the latest user question \\\n",
        "which might reference context in the chat history, formulate a standalone question \\\n",
        "which can be understood without the chat history. Do NOT answer the question, \\\n",
        "just reformulate it if needed and otherwise return it as is.\n",
        "\"\"\"\n",
        "\n",
        "contextualize_q_prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", contextualize_q_system_prompt),\n",
        "        MessagesPlaceholder(\"chat_history\"),\n",
        "        (\"human\", \"{input}\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "history_aware_retriever = create_history_aware_retriever(\n",
        "    llm, ensemble_retriever, contextualize_q_prompt\n",
        ")\n",
        "\n",
        "qa_system_prompt = \"\"\"\n",
        "You are an artwork specialist. You must assist the users in finding, describing, and displaying artworks related to the Belgian monarchy. \\\n",
        "You first have to search answers in the \"Knowledge Base\". If no answers are found in the \"Knowledge Base\", then answer with your own knowledge. \\\n",
        "You have to answer in the same language as the question.\n",
        "At the end of the answer:\n",
        "- give a link to a web page about the artwork (see the \"url\" field).\n",
        "- display an image of the artwork (see the \"og:image\" field).\n",
        "\n",
        "Knowledge Base:\n",
        "\n",
        "{context}\n",
        "\"\"\"\n",
        "\n",
        "qa_prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", qa_system_prompt),\n",
        "        MessagesPlaceholder(\"chat_history\"),\n",
        "        (\"human\", \"{input}\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "question_answer_chain = create_stuff_documents_chain(llm, qa_prompt)\n",
        "\n",
        "ai_assistant_chain = create_retrieval_chain(history_aware_retriever, question_answer_chain)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P_Vs5q4pAiWZ"
      },
      "source": [
        "Query the AI Assistant:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5iMV6D16T5y8"
      },
      "outputs": [],
      "source": [
        "question = \"Pouvez-vous me montrer le tableau 'La revue des Ã©coles' ?\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"Qui a peint ce tableau ?\""
      ],
      "metadata": {
        "id": "rkeT6gTMlpZ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"Quelle est la dimension du tableau ?\""
      ],
      "metadata": {
        "id": "LESYfyp0rs4V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"Pouvez-vous me montrer un tableau de Charles Porion ?\""
      ],
      "metadata": {
        "id": "nqH2WKWeaqO5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"Quel est la date de naissance du peintre ?\""
      ],
      "metadata": {
        "id": "MM_Wj8zvb8UR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"Quel est la date de naissance de Guy de Greef ?\""
      ],
      "metadata": {
        "id": "Lfl-Coe5LOAT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"Que possÃ¨de Gertrude Baelde ?\""
      ],
      "metadata": {
        "id": "_3VJe8O4D181"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"Camille Van Camp a-t-il fait des croquis pour sa peinture 'La fÃªte patriotique ' ?\""
      ],
      "metadata": {
        "id": "Wu7YZfAYE-CZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#answer = ai_assistant_chain.invoke(question) # Without memory"
      ],
      "metadata": {
        "id": "TVCnHqzq0jhQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "djaCokNX46hX"
      },
      "outputs": [],
      "source": [
        "output = ai_assistant_chain.invoke({\"input\": question, \"chat_history\": chat_history}) # output is a dictionary. output[\"answer\"] is in markdown format."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat_history.extend([HumanMessage(content=question), output[\"answer\"]])"
      ],
      "metadata": {
        "id": "nS3uFmchgR8U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(output[\"answer\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ha7DuSyBxBkQ",
        "outputId": "bb8227a1-6a63-4f67-a885-9b85d9588502"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Le tableau \"La revue des Ã©coles en 1878\" de Jan Verhas reprÃ©sente un Ã©vÃ©nement marquant oÃ¹ environ 23.000 Ã©lÃ¨ves des Ã©coles bruxelloises ont dÃ©filÃ© devant le roi LÃ©opold II et la reine Marie-Henriette Ã  l'occasion de leurs noces d'argent. Cette Åuvre, achevÃ©e en 1880, a Ã©tÃ© exposÃ©e lors de l'Exposition historique de l'art belge et a connu un grand succÃ¨s public. Le tableau montre la place des Palais Ã  Bruxelles et inclut des portraits de figures notables de l'Ã©poque.\n",
            "\n",
            "Pour plus d'informations sur l'Åuvre, vous pouvez visiter le lien suivant : [BALaT KIK-IRPA](https://balat.kikirpa.be/object/130731)\n",
            "\n",
            "Voici une image du tableau :\n",
            "![La revue des Ã©coles en 1878](http://balat.kikirpa.be/image/thumbnail/B213530.jpg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(chat_history)"
      ],
      "metadata": {
        "id": "6O1cK9VlxO05"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qrFCZTwc1sMU"
      },
      "outputs": [],
      "source": [
        "# Query the vector RAG only\n",
        "docs = vector_db.similarity_search(question, k=2) # List of Documents; page_content of a Document: string\n",
        "print(docs)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1BsLmoXvIqZAA5IjHZc3ik-qh06OEm18c",
      "authorship_tag": "ABX9TyM7cVAtvB7YtlQy9oWBrsq9",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}